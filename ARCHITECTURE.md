# ğŸ“š Arquitetura do Backend - RSS Feed Extractor

Este documento detalha a arquitetura completa do backend, incluindo banco de dados, cache, serviÃ§os e fluxos de dados.

---

## ğŸ“‹ Ãndice

1. [VisÃ£o Geral](#-visÃ£o-geral)
2. [Stack TecnolÃ³gica](#-stack-tecnolÃ³gica)
3. [Estrutura de DiretÃ³rios](#-estrutura-de-diretÃ³rios)
4. [Banco de Dados PostgreSQL](#-banco-de-dados-postgresql)
5. [Cache Redis (Upstash)](#-cache-redis-upstash)
6. [API REST](#-api-rest)
7. [ServiÃ§os](#-serviÃ§os)
8. [Workers e Scheduler](#-workers-e-scheduler)
9. [Fluxos de Dados](#-fluxos-de-dados)
10. [Eventos em Tempo Real (SSE)](#-eventos-em-tempo-real-sse)
11. [VariÃ¡veis de Ambiente](#-variÃ¡veis-de-ambiente)

---

## ğŸ¯ VisÃ£o Geral

O sistema Ã© um **agregador de notÃ­cias inteligente** que:
1. Faz **scraping** de sites de notÃ­cias
2. **Classifica** artigos automaticamente usando IA (Gemini)
3. **Gera feeds RSS/JSON** agregados
4. Notifica clientes em **tempo real** via SSE
5. Permite **bookmarks** de artigos favoritos

### Fluxo Principal

```
Sites cadastrados â†’ Scraping automÃ¡tico â†’ DeduplicaÃ§Ã£o Redis â†’ 
Salvamento PostgreSQL â†’ ClassificaÃ§Ã£o Gemini â†’ Broadcast SSE â†’ 
Frontend atualizado em tempo real
```

---

## ğŸ›  Stack TecnolÃ³gica

| Tecnologia | Uso |
|------------|-----|
| **Node.js** | Runtime |
| **Express** | Framework web |
| **PostgreSQL** | Banco de dados principal |
| **Upstash Redis** | Cache e deduplicaÃ§Ã£o |
| **Google Gemini** | ClassificaÃ§Ã£o de artigos com IA |
| **Cheerio** | Parser HTML para scraping |
| **node-cron** | Agendamento de tarefas |
| **RSS** | GeraÃ§Ã£o de feeds RSS 2.0 |

### DependÃªncias Principais

```json
{
  "@google/generative-ai": "^0.24.1",    // Gemini AI
  "@upstash/redis": "^1.35.7",           // Cache
  "axios": "^1.6.0",                      // HTTP client
  "cheerio": "^1.0.0-rc.12",             // HTML parser
  "express": "^4.18.2",                   // Web framework
  "node-cron": "^3.0.3",                  // Scheduler
  "pg": "^8.11.3",                        // PostgreSQL
  "robots-parser": "^3.0.1",              // Respeitar robots.txt
  "rss": "^1.2.2"                         // Gerar feeds RSS
}
```

---

## ğŸ“ Estrutura de DiretÃ³rios

```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ database.js      # Pool de conexÃµes PostgreSQL
â”‚   â”‚   â”œâ”€â”€ redis.js         # Cliente Upstash Redis + helpers
â”‚   â”‚   â””â”€â”€ migrate.js       # Script de migraÃ§Ã£o
â”‚   â”‚
â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”œâ”€â”€ articlesController.js   # CRUD de artigos
â”‚   â”‚   â”œâ”€â”€ categoriesController.js # Listagem de categorias
â”‚   â”‚   â”œâ”€â”€ feedsController.js      # GeraÃ§Ã£o de feeds RSS/JSON
â”‚   â”‚   â”œâ”€â”€ sitesController.js      # CRUD de sites
â”‚   â”‚   â””â”€â”€ adminController.js      # FunÃ§Ãµes administrativas
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ Article.js       # Model de artigos
â”‚   â”‚   â”œâ”€â”€ Category.js      # Model de categorias
â”‚   â”‚   â”œâ”€â”€ Site.js          # Model de sites
â”‚   â”‚   â””â”€â”€ ScrapingLog.js   # Model de logs
â”‚   â”‚
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ articles.js      # /api/articles
â”‚   â”‚   â”œâ”€â”€ categories.js    # /api/categories
â”‚   â”‚   â”œâ”€â”€ feeds.js         # /feeds
â”‚   â”‚   â”œâ”€â”€ sites.js         # /api/sites
â”‚   â”‚   â”œâ”€â”€ admin.js         # /api/admin
â”‚   â”‚   â””â”€â”€ events.js        # /api/events (SSE)
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ scraperService.js          # ExtraÃ§Ã£o de artigos
â”‚   â”‚   â”œâ”€â”€ geminiClassifierService.js # ClassificaÃ§Ã£o via Gemini
â”‚   â”‚   â”œâ”€â”€ classifierService.js       # ClassificaÃ§Ã£o local (backup)
â”‚   â”‚   â”œâ”€â”€ feedGeneratorService.js    # GeraÃ§Ã£o de feeds
â”‚   â”‚   â””â”€â”€ sseManager.js              # Gerenciador de conexÃµes SSE
â”‚   â”‚
â”‚   â”œâ”€â”€ workers/
â”‚   â”‚   â”œâ”€â”€ scrapingWorker.js    # Worker de scraping
â”‚   â”‚   â”œâ”€â”€ classifierWorker.js  # Worker de classificaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ cleanupWorker.js     # Worker de limpeza
â”‚   â”‚
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â””â”€â”€ jobs.js          # Cron jobs agendados
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ rateLimiter.js   # Rate limiting + robots.txt
â”‚   â”‚   â””â”€â”€ deduplication.js # FunÃ§Ãµes de deduplicaÃ§Ã£o
â”‚   â”‚
â”‚   â””â”€â”€ server.js            # Entry point
â”‚
â””â”€â”€ migrations/
    â”œâ”€â”€ 001_initial_schema.sql  # Schema inicial
    â””â”€â”€ 002_add_bookmarks.sql   # Adiciona bookmarks
```

---

## ğŸ—„ Banco de Dados PostgreSQL

### Diagrama ER

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          SITES                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id              SERIAL PRIMARY KEY                              â”‚
â”‚ name            VARCHAR(255) NOT NULL                           â”‚
â”‚ url             VARCHAR(500) NOT NULL UNIQUE                    â”‚
â”‚ category        VARCHAR(100)                                    â”‚
â”‚ scraping_method VARCHAR(50) DEFAULT 'auto'                      â”‚
â”‚ last_scraped_at TIMESTAMP                                       â”‚
â”‚ scraping_interval INTEGER DEFAULT 3600  (segundos)              â”‚
â”‚ active          BOOLEAN DEFAULT true                            â”‚
â”‚ created_at      TIMESTAMP DEFAULT NOW()                         â”‚
â”‚ updated_at      TIMESTAMP DEFAULT NOW()  (trigger automÃ¡tico)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ 1:N
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ARTICLES                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id                  SERIAL PRIMARY KEY                          â”‚
â”‚ site_id             INTEGER REFERENCES sites(id) ON DELETE CASCADE â”‚
â”‚ title               TEXT NOT NULL                               â”‚
â”‚ url                 VARCHAR(1000) NOT NULL UNIQUE               â”‚
â”‚ summary             TEXT                                        â”‚
â”‚ content             TEXT                                        â”‚
â”‚ image_url           VARCHAR(1000)                               â”‚
â”‚ author              VARCHAR(255)                                â”‚
â”‚ published_at        TIMESTAMP                                   â”‚
â”‚ scraped_at          TIMESTAMP DEFAULT NOW()                     â”‚
â”‚ category            VARCHAR(100)        â† ClassificaÃ§Ã£o IA      â”‚
â”‚ category_confidence FLOAT               â† ConfianÃ§a 0-1         â”‚
â”‚ bookmarked          BOOLEAN DEFAULT false â† Preserva na limpeza â”‚
â”‚ created_at          TIMESTAMP DEFAULT NOW()                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        CATEGORIES                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id          SERIAL PRIMARY KEY                                  â”‚
â”‚ name        VARCHAR(100) NOT NULL UNIQUE                        â”‚
â”‚ slug        VARCHAR(100) NOT NULL UNIQUE                        â”‚
â”‚ description TEXT                                                â”‚
â”‚ created_at  TIMESTAMP DEFAULT NOW()                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SCRAPING_LOGS                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ id                SERIAL PRIMARY KEY                            â”‚
â”‚ site_id           INTEGER REFERENCES sites(id) ON DELETE CASCADEâ”‚
â”‚ status            VARCHAR(50) NOT NULL  ('success' | 'failed')  â”‚
â”‚ articles_found    INTEGER DEFAULT 0                             â”‚
â”‚ error_message     TEXT                                          â”‚
â”‚ scraping_duration INTEGER (milissegundos)                       â”‚
â”‚ created_at        TIMESTAMP DEFAULT NOW()                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Categorias PadrÃ£o

```sql
'FÃ³rmula 1', 'Futebol', 'Esportes', 'Economia', 'PolÃ­tica',
'Tecnologia', 'Entretenimento', 'NegÃ³cios', 'Mundo', 'Brasil',
'SaÃºde', 'EducaÃ§Ã£o', 'CiÃªncia', 'Meio Ambiente', 'SeguranÃ§a',
'ReligiÃ£o', 'AutomÃ³veis', 'Games'
```

### Ãndices

```sql
-- Performance de consultas
CREATE INDEX idx_articles_site_id ON articles(site_id);
CREATE INDEX idx_articles_category ON articles(category);
CREATE INDEX idx_articles_published_at ON articles(published_at DESC NULLS LAST);
CREATE INDEX idx_articles_url ON articles(url);
CREATE INDEX idx_articles_bookmarked ON articles(bookmarked) WHERE bookmarked = true;
CREATE INDEX idx_scraping_logs_site_id ON scraping_logs(site_id);
CREATE INDEX idx_scraping_logs_created_at ON scraping_logs(created_at DESC);
```

### Trigger de AtualizaÃ§Ã£o

```sql
-- Atualiza updated_at automaticamente em sites
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_sites_updated_at
  BEFORE UPDATE ON sites
  FOR EACH ROW
  EXECUTE FUNCTION update_updated_at_column();
```

### ConfiguraÃ§Ã£o de ConexÃ£o

```javascript
const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
  ssl: { rejectUnauthorized: false },  // Para Render/Heroku
  max: 20,                              // MÃ¡ximo de conexÃµes
  idleTimeoutMillis: 30000,             // 30s idle
  connectionTimeoutMillis: 2000         // 2s timeout
});
```

---

## ğŸ”´ Cache Redis (Upstash)

### PropÃ³sito

O Redis Ã© usado para:
1. **DeduplicaÃ§Ã£o de artigos** - Evita processar o mesmo artigo duas vezes
2. **Rate limiting** - Controla requisiÃ§Ãµes por domÃ­nio
3. **Cache temporÃ¡rio** - TTL de 24h para deduplicaÃ§Ã£o

### Estrutura de Chaves

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CHAVES REDIS                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  DEDUPLICAÃ‡ÃƒO (TTL: 24h)                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  dedup:url:{md5_hash}    â†’ "1"   (URL jÃ¡ processada)            â”‚
â”‚  dedup:title:{md5_hash}  â†’ "1"   (TÃ­tulo jÃ¡ processado)         â”‚
â”‚                                                                  â”‚
â”‚  RATE LIMITING (TTL: 15min)                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚  ratelimit:{domain}      â†’ count (Contador de requisiÃ§Ãµes)      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### FunÃ§Ãµes de Cache

```javascript
// Verificar duplicaÃ§Ã£o
async function isDuplicate(url, title) {
  const normalizedUrl = normalizeUrl(url);
  const titleHash = hashTitle(title);
  
  // Verifica URL
  const urlKey = `dedup:url:${md5(normalizedUrl)}`;
  if (await cache.exists(urlKey)) {
    return { isDuplicate: true, reason: 'url' };
  }
  
  // Verifica tÃ­tulo
  const titleKey = `dedup:title:${titleHash}`;
  if (await cache.exists(titleKey)) {
    return { isDuplicate: true, reason: 'title' };
  }
  
  return { isDuplicate: false };
}

// Marcar como processado (TTL 24h)
async function markAsProcessed(url, title) {
  await cache.set(`dedup:url:${hash}`, '1', 86400);
  await cache.set(`dedup:title:${hash}`, '1', 86400);
}
```

### NormalizaÃ§Ã£o de URL

Remove parÃ¢metros de tracking antes de gerar hash:

```javascript
function normalizeUrl(url) {
  const parsed = new URL(url);
  // Remove UTMs e tracking
  parsed.searchParams.delete('utm_source');
  parsed.searchParams.delete('utm_medium');
  parsed.searchParams.delete('utm_campaign');
  parsed.searchParams.delete('ref');
  parsed.searchParams.delete('fbclid');
  parsed.searchParams.delete('gclid');
  return parsed.href.toLowerCase().replace(/\/$/, '');
}
```

---

## ğŸŒ API REST

### Endpoints de Sites

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/api/sites` | Lista todos os sites |
| `GET` | `/api/sites/:id` | Detalhes de um site |
| `GET` | `/api/sites/:id/stats` | EstatÃ­sticas do site |
| `GET` | `/api/sites/:id/articles` | Artigos do site |
| `POST` | `/api/sites` | Cria novo site |
| `POST` | `/api/sites/test` | Testa scraping de URL |
| `PUT` | `/api/sites/:id` | Atualiza site |
| `DELETE` | `/api/sites/:id` | Remove site e artigos |
| `POST` | `/api/sites/:id/scrape` | ForÃ§a scraping imediato |

### Endpoints de Artigos

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/api/articles` | Lista artigos (filtros: category, limit, offset) |
| `GET` | `/api/articles/:id` | Detalhes de um artigo |
| `GET` | `/api/articles/stats` | EstatÃ­sticas gerais |
| `GET` | `/api/articles/stats/by-category` | EstatÃ­sticas por categoria |
| `GET` | `/api/articles/bookmarked` | Lista artigos salvos |
| `POST` | `/api/articles/:id/bookmark` | Salva artigo |
| `DELETE` | `/api/articles/:id/bookmark` | Remove dos salvos |

### Endpoints de Categorias

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `GET` | `/api/categories` | Lista todas as categorias |
| `GET` | `/api/categories/:slug` | Detalhes de uma categoria |
| `GET` | `/api/categories/:slug/stats` | EstatÃ­sticas da categoria |

### Endpoints de Feeds RSS/JSON

| Endpoint | DescriÃ§Ã£o |
|----------|-----------|
| `/feeds/sites/:id.rss` | Feed RSS de um site |
| `/feeds/sites/:id.json` | Feed JSON de um site |
| `/feeds/categories/:slug.rss` | Feed RSS de uma categoria |
| `/feeds/categories/:slug.json` | Feed JSON de uma categoria |
| `/feeds/all.rss` | Feed RSS combinado (todos os sites) |
| `/feeds/all.json` | Feed JSON combinado |

### Endpoints Administrativos

| MÃ©todo | Endpoint | DescriÃ§Ã£o |
|--------|----------|-----------|
| `POST` | `/api/admin/clear-cache` | Limpa artigos Ã³rfÃ£os do PostgreSQL |

---

## âš™ï¸ ServiÃ§os

### 1. ScraperService

ResponsÃ¡vel por extrair artigos de sites de notÃ­cias.

```javascript
// Fluxo do scraping
async scrapeSite(siteId) {
  // 1. Busca site no banco
  const site = await Site.findById(siteId);
  
  // 2. Faz requisiÃ§Ã£o respeitando rate limit e robots.txt
  const response = await fetchWithRateLimit(site.url);
  
  // 3. Parse HTML com Cheerio
  const $ = cheerio.load(response.data);
  
  // 4. Remove elementos desnecessÃ¡rios
  $('script, style, noscript, iframe, nav, footer, header, aside').remove();
  
  // 5. Extrai artigos usando seletores inteligentes
  const articles = await extractArticles($, site.url);
  
  // 6. Para cada artigo:
  for (const article of articles) {
    // Verifica deduplicaÃ§Ã£o no Redis
    const dupl = await isDuplicate(article.url, article.title);
    if (dupl.isDuplicate) continue;
    
    // Busca imagem se nÃ£o encontrou
    if (!article.imageUrl) {
      article.imageUrl = await extractImageFromArticlePage(article.url);
    }
    
    // Salva no PostgreSQL
    const saved = await Article.create({ siteId: site.id, ...article });
    
    // Classifica via Gemini (se rate limited, fica na fila)
    const classified = await GeminiClassifier.classifyArticle(article.title, article.summary);
    if (classified) {
      await Article.updateCategory(saved.id, classified.category, classified.confidence);
    }
    
    // Marca como processado no Redis
    await markAsProcessed(article.url, article.title);
  }
  
  // 7. Atualiza last_scraped_at
  await Site.updateLastScraped(siteId);
  
  // 8. Registra log de scraping
  await ScrapingLog.create({ siteId, status: 'success', articlesFound: articles.length });
}
```

**Seletores de Artigos (prioridade)**:
1. `article[itemtype*="NewsArticle"]` - Schema.org
2. `article` - SemÃ¢ntico HTML5
3. `a[href*="/noticia"]`, `a[href*="/news/"]` - Links diretos
4. `[class*="news-item"]`, `[class*="post-item"]` - Classes comuns
5. Seletores especÃ­ficos para G1, UOL, Climatempo, etc.

**ExtraÃ§Ã£o de Imagens (algoritmo de pontuaÃ§Ã£o)**:
1. Meta tags `og:image` e `twitter:image` (+alto)
2. JSON-LD structured data
3. `figure img`, `picture img`
4. Classes `wp-post-image`, `featured-img`
5. Atributos `data-src`, `data-lazy-src` (lazy loading)
6. Sistema de pontuaÃ§Ã£o baseado em tamanho, posiÃ§Ã£o e classe

---

### 2. GeminiClassifierService

Classifica artigos usando Google Gemini AI.

```javascript
async classifyArticle(title, summary = '') {
  const prompt = `
    VocÃª Ã© um classificador de notÃ­cias brasileiras. Retorne APENAS JSON vÃ¡lido.
    
    TEXTO: "${title}. ${summary}"
    
    CATEGORIAS: FÃ³rmula 1, Futebol, Esportes, Economia, PolÃ­tica, Tecnologia, ...
    
    FORMATO: {"category":"CATEGORIA","confidence":0.95,"location":"ESTADO_OU_null"}
    
    REGRAS:
    1. TIMES DE FUTEBOL NÃƒO SÃƒO LOCALIZAÃ‡ÃƒO
    2. LOCATION sÃ³ Ã© preenchido se menciona um LUGAR GEOGRÃFICO
  `;
  
  const response = await axios.post(GEMINI_API_URL, { prompt }, { key: apiKey });
  
  return {
    category: parsed.category,      // "Tecnologia"
    confidence: parsed.confidence,  // 0.95
    location: parsed.location,      // "SÃ£o Paulo" ou null
    method: 'gemini'
  };
}
```

**Rate Limiting**:
- Delay de 1s entre requests
- Se 429 (rate limit), espera 60s
- Artigos nÃ£o classificados ficam na fila para retry pelo worker

---

### 3. FeedGeneratorService

Gera feeds RSS 2.0 e JSON Feed.

```javascript
// Gera RSS 2.0 com namespace media:
generateRSS(feedData, articles) {
  const feed = new RSS({
    title: feedData.title,
    description: feedData.description,
    feed_url: feedData.feed_url,
    site_url: feedData.site_url,
    language: 'pt-BR',
    custom_namespaces: { 'media': 'http://search.yahoo.com/mrss/' }
  });
  
  for (const article of articles) {
    feed.item({
      title: article.title,
      url: article.url,
      date: article.published_at,
      description: article.summary,
      categories: [article.category],
      enclosure: article.image_url ? { url: article.image_url, type: 'image/jpeg' } : null,
      custom_elements: [
        { 'media:thumbnail': { _attr: { url: article.image_url } } }
      ]
    });
  }
  
  return feed.xml({ indent: true });
}
```

---

### 4. SSEManager

Gerencia conexÃµes SSE (Server-Sent Events) para atualizaÃ§Ã£o em tempo real.

```javascript
class SSEManager {
  // Map<Response, { categories: Set|null, sites: Set|null }>
  clients = new Map();
  
  // Adiciona cliente com filtros
  addClient(res, { categories, sites }) {
    this.clients.set(res, {
      categories: categories ? new Set(categories.map(normalizeCategory)) : null,
      sites: sites ? new Set(sites) : null
    });
  }
  
  // Broadcast filtrado - sÃ³ envia para clientes interessados
  broadcastFiltered(event, data) {
    for (const [client, subscriptions] of this.clients) {
      if (this.shouldReceive(subscriptions, data.category, data.site_id)) {
        client.write(`event: ${event}\ndata: ${JSON.stringify(data)}\n\n`);
      }
    }
  }
  
  // Heartbeat a cada 30s para manter conexÃµes vivas
  startHeartbeat() {
    setInterval(() => {
      this.broadcast('heartbeat', { timestamp: new Date().toISOString() });
    }, 30000);
  }
}
```

**Eventos SSE**:
- `connected` - ConexÃ£o estabelecida
- `heartbeat` - Keep-alive (30s)
- `new_article` - Novo artigo classificado

**Filtros de Subscription**:
```
GET /api/events                              â†’ Recebe TUDO
GET /api/events?categories=tecnologia        â†’ SÃ³ Tecnologia
GET /api/events?categories=tecnologia,futebol&sites=1,5  â†’ Tecnologia e Futebol, sites 1 e 5
```

---

## â° Workers e Scheduler

### Cron Jobs

```javascript
// jobs.js
Scheduler.start() {
  // 1. SCRAPING - A cada 30 minutos
  cron.schedule('*/30 * * * *', () => ScrapingWorker.run());
  
  // 2. CLASSIFICAÃ‡ÃƒO - A cada 5 minutos
  cron.schedule('*/5 * * * *', () => ClassifierWorker.run());
  
  // 3. LIMPEZA - Todo dia Ã s 03:00
  cron.schedule('0 3 * * *', () => CleanupWorker.run());
}
```

### ScrapingWorker

```javascript
async run() {
  // Busca sites que precisam de scraping
  // (last_scraped_at NULL ou diferenÃ§a > scraping_interval)
  const sites = await Site.findReadyToScrape();
  
  for (const site of sites) {
    await ScraperService.scrapeSite(site.id);
    await delay(2000); // Delay entre sites
  }
}
```

### ClassifierWorker

```javascript
async run() {
  // Processa artigos que nÃ£o foram classificados (fila do Gemini)
  const result = await GeminiClassifierService.processUncategorized(20);
  // Batch de 20 artigos por execuÃ§Ã£o
}
```

### CleanupWorker

```javascript
async run() {
  const RETENTION_DAYS = 3;
  
  // Remove artigos > 3 dias (EXCETO bookmarked)
  const deletedArticles = await Article.deleteOlderThan(RETENTION_DAYS);
  
  // Remove logs de scraping > 3 dias
  const deletedLogs = await ScrapingLog.deleteOlderThan(RETENTION_DAYS);
}
```

---

## ğŸ”„ Fluxos de Dados

### 1. Fluxo de Scraping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                            FLUXO DE SCRAPING                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Cron   â”‚â”€â”€â”€â–¶â”‚   Busca      â”‚â”€â”€â”€â–¶â”‚   Fetch     â”‚â”€â”€â”€â–¶â”‚     Parse       â”‚  â”‚
â”‚  â”‚ (30min) â”‚    â”‚   Sites      â”‚    â”‚   HTML      â”‚    â”‚    Cheerio      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   Prontos    â”‚    â”‚  (+robots)  â”‚    â”‚                 â”‚  â”‚
â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚           â”‚
â”‚                                                                 â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Broadcast     â”‚â—€â”€â”€â”€â”‚   Salva     â”‚â—€â”€â”€â”€â”‚      Verifica               â”‚  â”‚
â”‚  â”‚   SSE           â”‚    â”‚   PostgreSQL â”‚    â”‚      DuplicaÃ§Ã£o            â”‚  â”‚
â”‚  â”‚   (filtered)    â”‚    â”‚             â”‚    â”‚      (Redis)                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â”‚                                            â”‚
â”‚                                â–¼                                            â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                     â”‚   Classifica     â”‚                                    â”‚
â”‚                     â”‚   Gemini API     â”‚                                    â”‚
â”‚                     â”‚   (ou fila)      â”‚                                    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Fluxo de ClassificaÃ§Ã£o (Fila)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FLUXO DE CLASSIFICAÃ‡ÃƒO                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Cron   â”‚â”€â”€â”€â–¶â”‚  Busca Artigos  â”‚â”€â”€â”€â–¶â”‚   Gemini    â”‚â”€â”€â”€â–¶â”‚   Atualiza   â”‚  â”‚
â”‚  â”‚ (5min)  â”‚    â”‚  category=NULL  â”‚    â”‚    API      â”‚    â”‚   Artigo     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                   â”‚         â”‚
â”‚                                                                   â–¼         â”‚
â”‚                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                                              â”‚   Broadcast SSE           â”‚  â”‚
â”‚                                              â”‚   'new_article'           â”‚  â”‚
â”‚                                              â”‚   (clientes filtrados)    â”‚  â”‚
â”‚                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Fluxo de GeraÃ§Ã£o de Feed

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          FLUXO DE FEED RSS                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   GET /feeds/    â”‚â”€â”€â”€â–¶â”‚   Consulta      â”‚â”€â”€â”€â–¶â”‚   Gera RSS 2.0        â”‚  â”‚
â”‚  â”‚   all.rss        â”‚    â”‚   PostgreSQL    â”‚    â”‚   ou JSON Feed        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚   (articles)    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                â”‚
â”‚                                                                             â”‚
â”‚  Filtros disponÃ­veis:                                                       â”‚
â”‚  â€¢ /feeds/sites/:id.rss      â†’ Artigos de um site                          â”‚
â”‚  â€¢ /feeds/categories/:slug.rss â†’ Artigos de uma categoria                  â”‚
â”‚  â€¢ /feeds/all.rss?limit=100  â†’ Feed combinado com limite                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¡ Eventos em Tempo Real (SSE)

### ConexÃ£o do Cliente

```javascript
// Frontend
const eventSource = new EventSource('/api/events?categories=tecnologia,games');

eventSource.addEventListener('connected', (e) => {
  console.log('Conectado:', JSON.parse(e.data));
});

eventSource.addEventListener('new_article', (e) => {
  const article = JSON.parse(e.data);
  // Atualiza UI com novo artigo
});

eventSource.addEventListener('heartbeat', (e) => {
  // Keep-alive
});
```

### Formato dos Eventos

```
event: connected
data: {"message":"Connected to SSE","subscriptions":{"categories":["tecnologia"],"sites":"all"}}

event: heartbeat
data: {"timestamp":"2024-01-15T10:30:00.000Z","clients":5}

event: new_article
data: {"id":123,"title":"Nova descoberta...","category":"Tecnologia","site_id":5,...}
```

---

## ğŸ” VariÃ¡veis de Ambiente

```env
# Servidor
PORT=3000
BASE_URL=http://localhost:3000
NODE_ENV=development

# PostgreSQL
DATABASE_URL=postgresql://user:pass@host:5432/dbname

# Upstash Redis
UPSTASH_REDIS_REST_URL=https://xxx.upstash.io
UPSTASH_REDIS_REST_TOKEN=your_token

# Google Gemini
GEMINI_API_KEY=your_gemini_api_key

# Scraping
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
RESPECT_ROBOTS_TXT=true
RATE_LIMIT_WINDOW=900000        # 15 minutos em ms
RATE_LIMIT_MAX_REQUESTS=100     # Max requests por domÃ­nio
REQUEST_DELAY=1500              # Delay entre requests em ms
```

---

## ğŸ“Š EstatÃ­sticas e Monitoramento

### Endpoint de Health Check

```
GET /health
Response: { "status": "ok", "timestamp": "2024-01-15T10:30:00.000Z" }
```

### EstatÃ­sticas de Artigos

```
GET /api/articles/stats
Response: {
  "total_articles": 1523,
  "categorized": 1500,
  "articles_today": 45,
  "active_sites": 12,
  "total_categories": 18
}
```

### Status SSE

```
GET /api/events/status
Response: {
  "total": 5,
  "withCategoryFilter": 3,
  "withSiteFilter": 1,
  "noFilters": 1,
  "categories": { "tecnologia": 2, "futebol": 1 },
  "sites": { "1": 1 }
}
```

---

## ğŸš€ Como Executar

```bash
# Instalar dependÃªncias
npm install

# Rodar migrations
npm run migrate

# Desenvolvimento (com hot reload)
npm run dev

# ProduÃ§Ã£o
npm start
```

---

## ğŸ“ Resumo

| Componente | Responsabilidade |
|------------|-----------------|
| **PostgreSQL** | PersistÃªncia de sites, artigos, categorias e logs |
| **Redis** | DeduplicaÃ§Ã£o (24h TTL), rate limiting por domÃ­nio |
| **Gemini AI** | ClassificaÃ§Ã£o automÃ¡tica de artigos em 18 categorias |
| **Cheerio** | Parse HTML e extraÃ§Ã£o de artigos |
| **node-cron** | Agendamento: scraping (30min), classificaÃ§Ã£o (5min), limpeza (3AM) |
| **SSE** | NotificaÃ§Ãµes em tempo real para frontend |
| **RSS/JSON** | GeraÃ§Ã£o de feeds consumÃ­veis por leitores RSS |

O sistema foi projetado para ser:
- **Resiliente**: Fila de classificaÃ§Ã£o, retry automÃ¡tico
- **Respeitoso**: Rate limiting, robots.txt
- **Eficiente**: DeduplicaÃ§Ã£o, Ã­ndices otimizados
- **Real-time**: SSE com filtros por categoria/site
- **Limpo**: Auto-limpeza de artigos antigos (preserva bookmarks)

